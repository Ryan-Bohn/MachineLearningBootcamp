{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyODg3ijRHLnWiT7/ePThIhC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0UvQ-biIszXM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593528556223,"user_tz":300,"elapsed":2818,"user":{"displayName":"Ryan Bohn","photoUrl":"","userId":"10105580983845648832"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oclqj8a9vTbp","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3RDFhuCotCLz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593528917921,"user_tz":300,"elapsed":299,"user":{"displayName":"Ryan Bohn","photoUrl":"","userId":"10105580983845648832"}}},"source":["class Net(nn.Module):\n","  def __init__(self, n_features):\n","    super(Net, self).__init__()\n","    self.fc1 = nn.Linear(n_features, 5) #nodes\n","    self.fc2 = nn.Linear(5, 3)\n","    self.fc3 = nn.Linear(3, 1)\n","  def forward(self, x):\n","    x = F.relu(self.fc1(x))\n","    x = F.relu(self.fc2(x))\n","    return torch.sigmoid(self.fc3(x))"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"ppEZ6yPauau9","colab_type":"code","colab":{}},"source":["net = Net(X_train.shape[1])\n","print(net)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JckqaY9dvVw8","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #cuda means gpu, this statement is important becuase even though we type on a laptop we"],"execution_count":null,"outputs":[]}]}