{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch_homework.ipynb","provenance":[{"file_id":"1PL7Fh96gZ4LKrvpOUwPLudsLeAgv6qBD","timestamp":1593564614174}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"STkc9j_Ji3vR","colab_type":"text"},"source":["https://www.kaggle.com/jsphyg/weather-dataset-rattle-package"]},{"cell_type":"markdown","metadata":{"id":"FxYwxLJpkr9O","colab_type":"text"},"source":["###Preprocessing"]},{"cell_type":"code","metadata":{"id":"4_fMjOCFkKkF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"status":"ok","timestamp":1593609133087,"user_tz":300,"elapsed":16093,"user":{"displayName":"Ryan Bohn","photoUrl":"","userId":"10105580983845648832"}},"outputId":"ca9a81f2-3588-4d6b-84c9-f961eb8ddd78"},"source":["from google.colab import drive\n","drive.mount('/content/drive')#data set was in HM's googledrive and imported it"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hpNQoL5jk2Mz","colab_type":"code","colab":{}},"source":["import pandas as pd #python data manipulation library\n","from sklearn.model_selection import train_test_split #splits data into training and testing\n","\n","import torch #new machine learning tools from PyTorch (a new model file extension)\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0GqQrzekfx-","colab_type":"code","colab":{}},"source":["df = pd.read_csv(\"/content/drive/My Drive/MLBootcamp/Week Three/Day 12/weatherAUS.csv\") #tells computer to read the weather data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwaw1akHk78v","colab_type":"code","colab":{}},"source":["df['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True) #this is weather data after running it\n","df['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True) #one hot vector\n","df = df.dropna(how='any')\n","X = df[['Rainfall', 'Humidity3pm', 'RainToday', 'Pressure9am']] #features\n","y = df[['RainTomorrow']] #labels\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hSw3HqF9sfhE","colab_type":"text"},"source":["###PyTorch Model"]},{"cell_type":"code","metadata":{"id":"j0h-OsJ4lQj_","colab_type":"code","colab":{}},"source":["X_train = torch.from_numpy(X_train.to_numpy()).float() #numpy (matrix#) representation of data\n","y_train = torch.squeeze(torch.from_numpy(y_train.to_numpy()).float())\n","X_test = torch.from_numpy(X_test.to_numpy()).float()\n","y_test = torch.squeeze(torch.from_numpy(y_test.to_numpy()).float())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K4vvcp0Y_6gy","colab_type":"code","colab":{}},"source":["class Net(nn.Module): #this says it's class that takes a nearal net model. Base class for all nn models\n","  def __init__(self, n_features):\n","    super(Net, self).__init__() #I think self referes to the 4 starting feature.\n","    self.fc1 = nn.Linear(n_features, 5)#Number of features is 4, then 5, then 3, then 1\n","    self.fc2 = nn.Linear(5, 3) #5 nodes to 3 #nodes\n","    self.fc2point5 = nn.Linear(3, 3) \n","    self.fc3 = nn.Linear(3, 2)#Here is where I'm adding my layer for the homework!!!!!!!!!!!!\n","    self.fc4 = nn.Linear(2, 1) #Now my layers go from 4 to 5 to 3 to 2 to 1 layer\n","  def forward(self, x): #these next three steps are the activation layers\n","    x = F.relu(self.fc1(x)) #does Relu Function for the first layer (max between 0 and f(c1))\n","    x = F.relu(self.fc2(x)) #does Relu Function for the second layer (max between 0 and f(c2))\n","    x = F.leaky_relu(self.fc2point5(x))\n","    x = F.relu(self.fc3(x)) #Here is where I added Relu to my new third layer for homework!!!!!\n","    return torch.sigmoid(self.fc4(x)) #does the sigmoid function (bewteen 0 and 1) for the fourth layer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oos2YOll_8zt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"ok","timestamp":1593609149816,"user_tz":300,"elapsed":484,"user":{"displayName":"Ryan Bohn","photoUrl":"","userId":"10105580983845648832"}},"outputId":"bc45ee9f-fccd-4886-88cb-0d5f8c5a4f5b"},"source":["net = Net(X_train.shape[1]) #create a net that says we start with 4 features\n","print(net) #this prints the nets out and shows they go from 4 to 5 to 3 to 2 to 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Net(\n","  (fc1): Linear(in_features=4, out_features=5, bias=True)\n","  (fc2): Linear(in_features=5, out_features=3, bias=True)\n","  (fc2point5): Linear(in_features=3, out_features=3, bias=True)\n","  (fc3): Linear(in_features=3, out_features=2, bias=True)\n","  (fc4): Linear(in_features=2, out_features=1, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4U3oqVivm-0K","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #cuda means it's running on CPU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dqO0PrXbCIxu","colab_type":"code","colab":{}},"source":["num_epochs = 700 #changed from 500 to 700\n","net = net.to(device) #need this if you are switching type of training device\n","criterion = nn.BCELoss().to(device) #loss function\n","optimizer = optim.Adadelta(net.parameters()) # Homework answer. this makes the learning step adaptive. This does the gradient descent. .001 is the default learning rate.I made it lower so model \"skips more and hobbles less\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"84IofiucnXFb","colab_type":"code","colab":{}},"source":["X_train = X_train.to(device)\n","y_train = y_train.to(device)\n","X_test = X_test.to(device)\n","y_test = y_test.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s04ClKHi1uTs","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i47W47rDCyJD","colab_type":"code","colab":{}},"source":["def calculate_accuracy(y_true, y_pred): #these functions calculate accuracy\n","  predicted = y_pred.ge(.5).view(-1) #set to 0 if < 0.5, 1 if >= 0.5\n","  return (y_true == predicted).sum().float() / len(y_true)\n","\n","def round_tensor(t, decimal_places=3):\n","  return round(t.item(), decimal_places)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hlLhXEeTv6rQ","colab_type":"text"},"source":["###Training"]},{"cell_type":"code","metadata":{"id":"8WZxzyYnFHTH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":550},"executionInfo":{"status":"ok","timestamp":1593609168436,"user_tz":300,"elapsed":10836,"user":{"displayName":"Ryan Bohn","photoUrl":"","userId":"10105580983845648832"}},"outputId":"aea44437-1520-4fc2-a73e-d010d4c0496c"},"source":["for epoch in range(num_epochs):\n","    y_pred = net(X_train) ##important\n","    y_pred = torch.squeeze(y_pred)\n","    train_loss = criterion(y_pred, y_train) ##important\n","    if epoch % 100 == 0:\n","      train_acc = calculate_accuracy(y_train, y_pred) \n","      y_test_pred = net(X_test) \n","      y_test_pred = torch.squeeze(y_test_pred)\n","      test_loss = criterion(y_test_pred, y_test)\n","      test_acc = calculate_accuracy(y_test, y_test_pred)\n","\n","      model_file = {'model': Net(4),\n","          'state_dict': net.state_dict(),\n","          'optimizer' : optimizer.state_dict()}\n","\n","      torch.save(model_file, 'model%d.pth'% epoch)\n","\n","\n","      print(\n","f'''epoch {epoch}\n","Train set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n","Test  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n","''')\n","    optimizer.zero_grad() ##important, set the gradient to 0\n","    train_loss.backward() ##important, backward propagation\n","    optimizer.step() ##important, updates the optimizer\n","    \n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"},{"output_type":"stream","text":["epoch 0\n","Train set - loss: 0.632, accuracy: 0.78\n","Test  set - loss: 0.632, accuracy: 0.78\n","\n","epoch 100\n","Train set - loss: 0.571, accuracy: 0.78\n","Test  set - loss: 0.571, accuracy: 0.78\n","\n","epoch 200\n","Train set - loss: 0.539, accuracy: 0.78\n","Test  set - loss: 0.539, accuracy: 0.78\n","\n","epoch 300\n","Train set - loss: 0.529, accuracy: 0.78\n","Test  set - loss: 0.528, accuracy: 0.78\n","\n","epoch 400\n","Train set - loss: 0.527, accuracy: 0.78\n","Test  set - loss: 0.527, accuracy: 0.78\n","\n","epoch 500\n","Train set - loss: 0.527, accuracy: 0.78\n","Test  set - loss: 0.527, accuracy: 0.78\n","\n","epoch 600\n","Train set - loss: 0.527, accuracy: 0.78\n","Test  set - loss: 0.527, accuracy: 0.78\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zv6DVpxov9dJ","colab_type":"text"},"source":["###Inference"]},{"cell_type":"markdown","metadata":{"id":"PtZVQu0izT5V","colab_type":"text"},"source":["Make sure if you train on a GPU, you run the model on a GPU."]},{"cell_type":"code","metadata":{"id":"OLW-AamowOR4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":352},"executionInfo":{"status":"error","timestamp":1593564545886,"user_tz":300,"elapsed":728,"user":{"displayName":"Ryan Bohn","photoUrl":"","userId":"10105580983845648832"}},"outputId":"593d805f-e78e-4b70-a244-7f278f9c02f1"},"source":["def load_model(filepath):\n","    model_path = torch.load(filepath)\n","    model = model_path['model']\n","    model.load_state_dict(model_path['state_dict'])\n","    for parameter in model.parameters():\n","        parameter.requires_grad = False\n","\n","    model.eval() ##super important\n","    return model\n","\n","model = load_model('model900.pth')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-aea1d34b6f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model900.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-42-aea1d34b6f3f>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model900.pth'"]}]},{"cell_type":"code","metadata":{"id":"Qh4F6uz61MgC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593530344336,"user_tz":300,"elapsed":553,"user":{"displayName":"Haripriya Mehta","photoUrl":"","userId":"15516312456033537798"}},"outputId":"15292288-50cc-45bc-c638-cbdf2cc670d7"},"source":["model.cuda() #if on GPU, or don't need this line"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net(\n","  (fc1): Linear(in_features=4, out_features=5, bias=True)\n","  (fc2): Linear(in_features=5, out_features=3, bias=True)\n","  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"PEIIyghPzSZK","colab_type":"code","colab":{}},"source":["output = model(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7K4A8p9F1eqJ","colab_type":"code","colab":{}},"source":["y_pred = torch.squeeze(output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"97m1e2RO9qDf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593530417573,"user_tz":300,"elapsed":554,"user":{"displayName":"Haripriya Mehta","photoUrl":"","userId":"15516312456033537798"}},"outputId":"f00e14e0-2695-4421-a5a9-8eb9dadf4e4e"},"source":["calculate_accuracy(y_test, y_pred)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.7798, device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"quv2j1s_3P6X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1593531259373,"user_tz":300,"elapsed":695,"user":{"displayName":"Haripriya Mehta","photoUrl":"","userId":"15516312456033537798"}},"outputId":"22ec9c00-4489-48bd-83dd-752446a5be47"},"source":["model.state_dict()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('fc1.weight', tensor([[-0.2364, -0.0062, -0.5604,  0.1197],\n","                      [ 0.1397, -0.4747, -0.1354, -0.4556],\n","                      [-0.1248,  0.3450,  0.0423,  0.4136],\n","                      [-0.0800,  0.4399, -0.1816,  0.0870],\n","                      [ 0.0427, -0.3346, -0.4804, -0.4379]], device='cuda:0')),\n","             ('fc1.bias',\n","              tensor([ 0.0782, -0.3728,  0.2775, -0.0620,  0.1338], device='cuda:0')),\n","             ('fc2.weight',\n","              tensor([[ 0.0768, -0.1645, -0.0829, -0.0797,  0.2555],\n","                      [ 0.0835,  0.2095, -0.4398, -0.0050, -0.1596],\n","                      [ 0.3616, -0.4206,  0.0112, -0.4096, -0.3411]], device='cuda:0')),\n","             ('fc2.bias',\n","              tensor([-0.1562,  0.4329,  0.1964], device='cuda:0')),\n","             ('fc3.weight',\n","              tensor([[ 0.2798,  0.1290, -0.4579]], device='cuda:0')),\n","             ('fc3.bias', tensor([-0.1769], device='cuda:0'))])"]},"metadata":{"tags":[]},"execution_count":28}]}]}